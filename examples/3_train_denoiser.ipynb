{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the trained noise model to guide the training of a VAE for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12b4f42-e9e0-4261-b740-77a97bb9f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tifffile import imread\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from noise_model.PixelCNN import PixelCNN\n",
    "from HDN.models.lvae import LadderVAE\n",
    "from utils.dataloaders import create_dn_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f74c5f-c93c-4d50-aa62-edfe179df167",
   "metadata": {},
   "source": [
    "Load noisy images\n",
    "These should be numpy ndarrays of shape [Number, Channels, Height, Width] or [Number, Height, Width]. </br>\n",
    "If working with 1-dimensional signals, the shape should be [Number, Channels, 1, Width] or [Number, 1, Width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d6de6a-5b86-43e4-96b9-d5936f470ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_location = \"../data/conv/observation.tif\"\n",
    "observation = imread(observation_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5eb3c-ddb4-4643-b935-493ad8bab88d",
   "metadata": {},
   "source": [
    "Load trained noise model and disable gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cc3352-96d3-48be-a0c8-31d7554f52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model_location = \"../nm_checkpoint/conv/final_params.ckpt\"\n",
    "noise_model = PixelCNN.load_from_checkpoint(noise_model_location).eval()\n",
    "\n",
    "for param in noise_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7961a-d92b-4162-af38-06cef2679784",
   "metadata": {},
   "source": [
    "Create data loaders and get the shape, mean and standard deviation of the noisy images.</br>\n",
    "Use the transforms argument to apply a torchvision transformation to images as they are loaded. E.g. `transform = transforms.RandomCrop(64)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd69b48-dae5-4f85-9dfc-fc3fd484906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "dn_train_loader, dn_val_loader, img_shape, data_mean, data_std = create_dn_loader(\n",
    "    observation, batch_size=8, split=0.8, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f1954-7bda-455e-9106-f99ab08c087c",
   "metadata": {},
   "source": [
    "Set denoiser checkpoint directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a0c501-3246-4eb0-bf7f-91b5ca4a5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_checkpoint_path = \"../dn_checkpoint/conv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d625debb",
   "metadata": {},
   "source": [
    "Initialise trainer and noise model.</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0fa1f",
   "metadata": {},
   "source": [
    "The defauly hyperparameters should work for most cases, but if training takes too long or an out of memory error is encountered, the `num_latents` can be decreased to `4`to reduce the size of the network while still getting good results. Alternatively, better performance could be achieved by increasing the `num_latents` to `8` and `z_dims` to `[64] * num_latents`.</br>\n",
    "Sometimes, increasing `dropout` to `0.1` or `0.2` can help when working with a limited amount of training data.</br>\n",
    "The `free_bits` value has the effect of setting the minimum amount of information expressed by the latent variables, information that will thus not be modelled by the decoder/noise model. Since our decoder/noise model is pretrained and frozen, the information it can model is predetermined and setting a `free_bits` value greater than zero should not be necessary. However, if the kl_loss is observed to drop very fast in tensorboard and plateau at a value less than ~1e-2, increasing the `free_bits` to `0.5`-`1.0` can help prevent the objective getting stuck in this undesirable equilibrium.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac5978-be0c-42c1-a426-404eb89bae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=dn_checkpoint_path,\n",
    "    accelerator=\"gpu\" if use_cuda else \"cpu\",\n",
    "    devices=[1],\n",
    "    max_epochs=500,\n",
    "    logger=TensorBoardLogger(dn_checkpoint_path),\n",
    "    log_every_n_steps=len(dn_train_loader),\n",
    "    callbacks=[LearningRateMonitor(logging_interval=\"epoch\")],\n",
    ")\n",
    "\n",
    "num_latents = 6\n",
    "z_dims = [32] * num_latents\n",
    "vae = LadderVAE(\n",
    "    z_dims=z_dims,\n",
    "    noiseModel=noise_model,\n",
    "    img_shape=img_shape,\n",
    "    gaussian_noise_std=None,\n",
    "    use_uncond_mode_at=[],\n",
    "    dropout=0.0,\n",
    "    free_bits=0.0,\n",
    "    data_mean=data_mean,\n",
    "    data_std=data_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c83726",
   "metadata": {},
   "source": [
    "Train and save final parameters</br>\n",
    "Training logs can be monitored on Tensorboard. Run the two cells below to activate it in the notebook. Alternatively, open a terminal, activate an environment with Tensorboard installed and enter `tensorboard --logdir path/to/autonoise/nm_checkpoint/` then open a browser and enter localhost:6006. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d95c6",
   "metadata": {},
   "source": [
    "The main metric to monitor here is the validation reconstruction loss, or val/reconstruction_loss. This should go down sharply at first then level off. The kl divergence, or kl_loss, is expected to go either up or down. The evidence lower bound, or elbo, is the sum of these two losses, and training should stop when both of these have plateaued. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef283ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57907ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ../dn_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ed2091-5c33-480b-9ea3-aa1a2eb70adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name             | Type                 | Params\n",
      "----------------------------------------------------------\n",
      "0 | first_bottom_up  | Sequential           | 75.8 K\n",
      "1 | top_down_layers  | ModuleList           | 4.1 M \n",
      "2 | bottom_up_layers | ModuleList           | 2.7 M \n",
      "3 | final_top_down   | Sequential           | 412 K \n",
      "4 | likelihood       | NoiseModelLikelihood | 5.3 M \n",
      "----------------------------------------------------------\n",
      "7.3 M     Trainable params\n",
      "5.3 M     Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.546    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]          Epoch 00198: reducing learning rate of group 0 to 1.5000e-04.\n",
      "Epoch 214: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00215: reducing learning rate of group 0 to 7.5000e-05.\n",
      "Epoch 231: 100%|██████████| 6/6 [00:02<00:00,  2.83it/s, v_num=1]Epoch 00232: reducing learning rate of group 0 to 3.7500e-05.\n",
      "Epoch 262: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00263: reducing learning rate of group 0 to 1.8750e-05.\n",
      "Epoch 279: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00280: reducing learning rate of group 0 to 9.3750e-06.\n",
      "Epoch 290: 100%|██████████| 6/6 [00:02<00:00,  2.83it/s, v_num=1]Epoch 00291: reducing learning rate of group 0 to 4.6875e-06.\n",
      "Epoch 301: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s, v_num=1]Epoch 00302: reducing learning rate of group 0 to 2.3437e-06.\n",
      "Epoch 312: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00313: reducing learning rate of group 0 to 1.1719e-06.\n",
      "Epoch 323: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00324: reducing learning rate of group 0 to 5.8594e-07.\n",
      "Epoch 334: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00335: reducing learning rate of group 0 to 2.9297e-07.\n",
      "Epoch 345: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00346: reducing learning rate of group 0 to 1.4648e-07.\n",
      "Epoch 356: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00357: reducing learning rate of group 0 to 7.3242e-08.\n",
      "Epoch 367: 100%|██████████| 6/6 [00:02<00:00,  2.83it/s, v_num=1]Epoch 00368: reducing learning rate of group 0 to 3.6621e-08.\n",
      "Epoch 378: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]Epoch 00379: reducing learning rate of group 0 to 1.8311e-08.\n",
      "Epoch 499: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(vae, dn_train_loader, dn_val_loader)\n",
    "trainer.save_checkpoint(os.path.join(dn_checkpoint_path, \"final_params.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cc1ac-34c7-44d6-8414-80ddf3a68733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
